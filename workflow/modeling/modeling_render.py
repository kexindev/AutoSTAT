import streamlit as st
import streamlit_antd_components as sac
from streamlit_ace import st_ace

from utils.sanitize_code import sanitize_code
from workflow.modeling.model_training import train_execution, modeling_code_gen, train_download_model
from workflow.modeling.model_inference import infer_load_data, infer_execution
from workflow.preprocessing.preprocessing_core import prep_meta_execution


def modeling_quick_actions(agent):

    st.write("é€‰æ‹©ä¸€ä¸ªæˆ–å¤šä¸ªmodelï¼š")
    selected_models = sac.chip(
        items=[
            sac.ChipItem(label='çº¿æ€§å›å½’'),
            sac.ChipItem(label='XGBoost'),
            sac.ChipItem(label='éšæœºæ£®æ—'),
            sac.ChipItem(label='ç¥ç»ç½‘ç»œ'),
        ], index=[0, 2], align='center', radius='md', color='#44658C', multiple=True
    )
    
    df = agent.load_df()

    if st.button("ğŸ–‹ï¸ å¿«é€Ÿå»ºæ¨¡"):
        if not selected_models:
            st.error("è¯·å…ˆé€‰æ‹©è®­ç»ƒmodelã€‚")
        else:
            with st.spinner("å»ºæ¨¡ Agent æ­£åœ¨ç”Ÿæˆè®­ç»ƒè„šæœ¬..."):
                raw = agent.code_generation(df.head().to_string(), selected_models)
                code = sanitize_code(raw)
                agent.save_code(code)
                agent.save_suggestion(selected_models)
                agent.save_user_selection(selected_models)
                st.success("è®­ç»ƒè„šæœ¬å·²ç”Ÿæˆå¹¶ä¿å­˜ã€‚")
                st.rerun()
                    
    return selected_models


def modeling_execution(agent, auto = False) -> None:

    code = agent.load_code()

    edited = st_ace(
        value=code,
        height=450,
        theme="tomorrow_night",
        language="python",
        auto_update=True
    )

    not_executed = agent.load_modeling_result() == None

    if edited is not None:
        if st.button("â–¶ï¸ æ‰§è¡Œå»ºæ¨¡", key="modeling_run_code") or (auto and not_executed):
            code = sanitize_code(edited)
            agent.save_code(code)
            train_execution(agent)
            agent.finish_auto()
            st.rerun()

        modeling_result = agent.load_modeling_result()
        if modeling_result is None:
            result_expand = False
        else:
            result_expand = True
            train_download_model(agent)
            with st.expander("è®­ç»ƒç»“æœ", result_expand):
                if modeling_result:
                    st.subheader("è®­ç»ƒç»“æœ")
                    try:
                        st.markdown(modeling_result)
                    except Exception:
                        st.write(modeling_result)


def modeling_inference(agent, preproc_agent):

    infer_load_data(agent)
    inference_processed_data = agent.load_inference_processed_df()
    inference_data = agent.load_inference_data()

    code = agent.load_inference_code()

    if st.button("â–¶ï¸ æ‰§è¡Œæ¨æ–­"):

        with st.spinner("æ­£åœ¨å¯¹æ¨ç†æ•°æ®è¿›è¡Œé¢„å¤„ç†..."):
 
            inference_data = agent.load_inference_data()
            if preproc_agent.code is not None:
                inference_processed_df = prep_meta_execution(preproc_agent, preproc_agent.code, inference_data)
                inference_data = inference_processed_df
            agent.save_inference_processed_df(inference_data)
            st.write("æ¨æ–­æ•°æ®é¢„è§ˆï¼š")
            st.dataframe(inference_data.head())

        with st.spinner("å»ºæ¨¡ Agent æ­£åœ¨ç”Ÿæˆæ¨ç†è„šæœ¬..."):
            
            raw = agent.code_generation_for_inference(agent.load_code(), inference_data.head())
            code = sanitize_code(raw)
            agent.save_inference_code(code)

    if code is not None:
        edited_code = st_ace(
            value=code,
            height=450,
            theme="tomorrow_night",
            language="python",
            auto_update=True
        )
        agent.save_inference_code(code)
        if st.button("â–¶ï¸ æ‰§è¡Œå»ºæ¨¡"):
            infer_execution(agent)


def modeling_chat(agent, auto) -> None:

    user_input = st.text_input("å»ºæ¨¡ç›®æ ‡", "é»˜è®¤")
    agent.save_target(user_input)

    with st.chat_message("assistant"):
        st.write(
            "æˆ‘æ˜¯ Autostat æ•°æ®åˆ†æåŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ï¼\n\n"
            "æ‚¨å¯ä»¥åœ¨ä¸‹æ–¹è¾“å…¥å»ºæ¨¡ç›¸å…³é—®é¢˜ï¼Œæˆ–ç›´æ¥ç‚¹å‡»æŒ‰é’®è·å–å»ºæ¨¡å»ºè®®ã€‚"
        )

        c = st.columns(2)
        with c[0]:
            analyze_btn = st.button("ğŸ” å»ºæ¨¡æ¨è", key='modeling_suggest', use_container_width=True)
        with c[1]:
            clear_modeling_suggest = st.button("â™»ï¸ æ¸…é™¤å»ºæ¨¡åˆ†æ", key='clear_modeling_suggest', use_container_width=True)
            if clear_modeling_suggest:
                agent.clear_memory()
                agent.suggestion = None

    chat_history = agent.load_memory()

    for idx, entry in enumerate(chat_history):
        bubble = st.chat_message(entry["role"])
        content = entry["content"]
        if isinstance(content, str):
            bubble.write(content)
        
    already_generated = any(
        entry["role"] == "assistant" and "æ¨¡" in str(entry["content"])
        for entry in chat_history
    )
    
    if analyze_btn or (auto and not already_generated):
        st.chat_message("user").write("è¯·å¸®æˆ‘è·å–å»ºæ¨¡å»ºè®®")
        agent.add_memory({"role": "user", "content": "è¯·å¸®æˆ‘è·å–å»ºæ¨¡å»ºè®®"})
        with st.spinner("åˆ†æä¸­..."):
            suggestion = agent.get_model_suggestion()
            agent.save_suggestion(suggestion)
            agent.refine_suggestions()
        st.chat_message("assistant").write(suggestion)
        agent.add_memory({"role": "assistant", "content": suggestion})
        st.chat_message("assistant").write("éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–ï¼Ÿå†æ¬¡ç‚¹å‡»æŒ‰é’®è·å–ä¸‹ä¸€æ¡å»ºè®®")
        agent.add_memory({"role": "assistant", "content": "éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–ï¼Ÿå†æ¬¡ç‚¹å‡»æŒ‰é’®è·å–ä¸‹ä¸€æ¡å»ºè®®"})

    user_input = st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼Œä¾‹å¦‚â€œå¦‚ä½•ä¼˜åŒ–è¿™ä¸ªæ¨¡å‹â€")
    if user_input:
        st.chat_message("user").write(user_input)
        agent.add_memory({"role": "user", "content": user_input})
        with st.spinner("å¤„ç†ä¸­â€¦"):
            reply = agent.get_model_suggestion(user_input)
            agent.save_suggestion(reply)
            agent.refine_suggestions()
        st.chat_message("assistant").write(reply)
        agent.add_memory({"role": "assistant", "content": reply})
        st.chat_message("assistant").write("éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–ï¼Ÿå†æ¬¡ç‚¹å‡»æŒ‰é’®è·å–ä¸‹ä¸€æ¡å»ºè®®")
        agent.add_memory({"role": "assistant", "content": "éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–ï¼Ÿå†æ¬¡ç‚¹å‡»æŒ‰é’®è·å–ä¸‹ä¸€æ¡å»ºè®®"})


if __name__ == "__main__":

    st.title("æ•°æ®å»ºæ¨¡")
    st.markdown("---")

    preproc_agent = st.session_state.data_preprocess_agent
    load_agent   = st.session_state.data_loading_agent

    processed_df = preproc_agent.load_processed_df()
    if processed_df is None:
        df = load_agent.load_df()
    else:
        df = processed_df

    if df is None:
        st.warning("âš ï¸ è¯·å…ˆåœ¨æ•°æ®å¯¼å…¥é¡µé¢åŠ è½½æ•°æ®")
        st.stop()

    agent = st.session_state.modeling_coding_agent
    agent.add_df(df)
    planner = st.session_state.planner_agent
    auto = planner.modeling_auto

    if st.session_state.auto_mode == True:
        if (agent.finish_auto_task == True and planner.switched_modeling == False) or planner.modeling_auto == False:
            planner.finish_modeling_auto()
            st.switch_page("workflow/report/report_render.py")

    code = agent.load_code()
    if code is None:
        expand = False
    else:
        expand = True

    inference_model = agent.load_best_model()
    if inference_model is None:
        inference_expand = False
    else:
        inference_expand = True

    c = st.columns(2)
    with c[0].expander('å¿«é€Ÿå»ºæ¨¡', True):
        modeling_quick_actions(agent)
    with c[1].expander('å»ºæ¨¡å»ºè®®', True):
        modeling_chat(agent, auto)
        modeling_code_gen(agent, auto=auto)
    with c[0].expander('å»ºæ¨¡æ‰§è¡Œ', expand):
        modeling_execution(agent, auto)
    # with c[0].expander('æ¨æ–­åˆ†æ', inference_expand):
    #     modeling_inference(agent, preproc_agent)
