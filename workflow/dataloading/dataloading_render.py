import os
from typing import List, Optional

import pandas as pd
import streamlit as st
import streamlit_antd_components as sac

from workflow.dataloading.dataloading_core import process_complex_data, load_from_path, load_concat_file, PathFileWrapper


def loading_data_file(agent):

    st.info(
        "ğŸ’¡ æç¤ºï¼š\n"
        "1. æ”¯æŒä¸€æ¬¡ä¸Šä¼ å¤šä¸ªæ•°æ®æ–‡ä»¶\n"
        "2. è‡ªåŠ¨ä½¿ç”¨å¤§æ¨¡å‹åˆ†æå¹¶å¤„ç†æ•°æ®\n"
        "3. æ”¯æŒå¤šç§æ ¼å¼çš„æ–‡ä»¶ç±»å‹ä¸Šä¼ \n"
    )

    selected_index = sac.tabs([
        sac.TabsItem(label='æœ¬åœ°ä¸Šä¼ '),
        # sac.TabsItem(label='è·¯å¾„å¯¼å…¥'),
    ], color='#5980AE',)

    if selected_index == "æœ¬åœ°ä¸Šä¼ ":
        # ç‚¹å‡»ä¸Šä¼ æ–‡ä»¶
        uploaded_files = st.file_uploader(
            "é€‰æ‹©æ–°æ–‡ä»¶",
            accept_multiple_files=True,
            help="æ‹–æ‹½æˆ–ç‚¹å‡»ä¸Šä¼ å¤šä¸ªæ–‡ä»¶ã€‚å¦‚æœä¸Šä¼ å¤šä¸ªæ ¼å¼ä¸åŒçš„æ–‡ä»¶ï¼Œå¯ä»¥é€‰æ‹©åˆ†åˆ«å¤„ç†ã€‚",
        )

        if uploaded_files:
            current_memory_file_name = agent.load_file_name()
            new_files = [f for f in uploaded_files if f.name not in current_memory_file_name]
            if new_files:
                try:
                    with st.spinner("æ­£åœ¨å¤„ç†æ•°æ®..."):
                        df, dfs, file_names = process_complex_data(new_files, agent)
                    if df is not None:
                        # ä¿å­˜æ–‡ä»¶ä¿¡æ¯
                        agent.save_dfs(dfs)
                        # ä¿å­˜æ–‡ä»¶åç§°åˆ—è¡¨
                        if not hasattr(agent, 'file_names_list'):
                            agent.file_names_list = []
                        agent.file_names_list = file_names
                        
                        # å¦‚æœæ˜¯å•ä¸ªæ–‡ä»¶ï¼Œç›´æ¥è®¾ç½®ä¸ºä¸»æ•°æ®
                        if len(dfs) == 1:
                            agent.add_df(df)
                            for f in new_files:
                                agent.save_file_name(f.name)
                            st.rerun()
                        else:
                            # å¤šä¸ªæ–‡ä»¶æ—¶ï¼Œå…ˆè®¾ç½®ç¬¬ä¸€ä¸ªä¸ºé»˜è®¤ï¼Œä½†ä¼šåœ¨ä¸‹é¢è®©ç”¨æˆ·é€‰æ‹©
                            agent.add_df(df)
                            for f in new_files:
                                agent.save_file_name(f.name)
                            st.rerun()
                except Exception as err:
                    st.error(f"å¯¼å…¥å¤±è´¥ï¼š{err}")

    elif selected_index == "è·¯å¾„å¯¼å…¥":
        # è·¯å¾„ä¸Šä¼ æ–‡ä»¶
        raw_paths = st.text_area(
            "ä»è·¯å¾„å¯¼å…¥æ•°æ® (æ¯è¡Œä¸€ä¸ªæ–‡ä»¶è·¯å¾„)",
            placeholder=    "C:\\data\\iris.names\nC:\\data\\iris.data",
            height=100
        )

        if st.button("ä»è·¯å¾„åŠ è½½æ–‡ä»¶", use_container_width=True):
            if raw_paths:

                path_list = [p.strip().strip("'\"") for p in raw_paths.strip().split('\n') if p.strip()]
                
                valid_paths = [p for p in path_list if os.path.exists(p)]
                invalid_paths = [p for p in path_list if not os.path.exists(p)]

                if invalid_paths:
                    st.warning(f"è·¯å¾„ä¸å­˜åœ¨ï¼Œå·²è·³è¿‡ï¼š\n- " + "\n- ".join(invalid_paths))

                if not valid_paths:
                    st.error("æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„æœ¬åœ°æ–‡ä»¶è·¯å¾„ã€‚")
                else:
                    current_memory_file_name = agent.load_file_name()
                    new_paths = [p for p in valid_paths if p not in current_memory_file_name]

                    if not new_paths:
                        st.info("æ‰€æœ‰æŒ‡å®šçš„è·¯å¾„æ–‡ä»¶å‡å·²åŠ è½½ã€‚")
                    else:
                        files_to_process = [PathFileWrapper(p) for p in new_paths]
                        try:
                            with st.spinner("æ­£åœ¨å¤„ç†æ•°æ®..."):
                                df, dfs, file_names = process_complex_data(files_to_process, agent)
                            if df is not None:
                                # ä¿å­˜æ–‡ä»¶ä¿¡æ¯
                                agent.save_dfs(dfs)
                                # ä¿å­˜æ–‡ä»¶åç§°åˆ—è¡¨
                                if not hasattr(agent, 'file_names_list'):
                                    agent.file_names_list = []
                                agent.file_names_list = file_names
                                
                                # å¦‚æœæ˜¯å•ä¸ªæ–‡ä»¶ï¼Œç›´æ¥è®¾ç½®ä¸ºä¸»æ•°æ®
                                if len(dfs) == 1:
                                    agent.add_df(df)
                                    for p in new_paths:
                                        agent.save_file_name(p)
                                    st.rerun()
                                else:
                                    # å¤šä¸ªæ–‡ä»¶æ—¶ï¼Œå…ˆè®¾ç½®ç¬¬ä¸€ä¸ªä¸ºé»˜è®¤ï¼Œä½†ä¼šåœ¨ä¸‹é¢è®©ç”¨æˆ·é€‰æ‹©
                                    agent.add_df(df)
                                    for p in new_paths:
                                        agent.save_file_name(p)
                                    st.rerun()
                        except Exception as err:
                            st.error(f"æœ¬åœ°æ–‡ä»¶è¯»å–å¤±è´¥ï¼š{err}")
    
    # å¦‚æœæœ‰å¤šä¸ªæ–‡ä»¶ï¼Œæ˜¾ç¤ºé€‰æ‹©ç•Œé¢
    dfs = agent.load_dfs()
    if dfs is not None and len(dfs) >= 2:
        # è·å–æ–‡ä»¶åç§°
        file_names = None
        if hasattr(agent, 'file_names_list') and agent.file_names_list:
            file_names = agent.file_names_list
        load_concat_file(dfs, agent, file_names)


def loading_basic_info(agent):
    
    df = agent.load_df()
    if df is not None:
        r, c = df.shape
        missing = int(df.isnull().sum().sum())
        col1, col2, col3 = st.columns(3)
        col1.metric("è¡Œæ•°", r)
        col2.metric("åˆ—æ•°", c)
        col3.metric("ç¼ºå¤±å€¼æ€»æ•°", missing)

        dtype_info = pd.DataFrame({
            "åˆ—å": df.columns,
            "ç±»å‹": df.dtypes.astype(str),
            "éç©º": df.count().values,
            "ç¼ºå¤±%": (df.isnull().mean() * 100).round(2).values,
        }).reset_index(drop=True)

        selected_index = sac.tabs([
            sac.TabsItem(label='æ•°æ®ç±»å‹æ¦‚è§ˆ'),
            sac.TabsItem(label='æ•°æ®é¢„è§ˆ'),
        ],color='#5980AE',)

        if selected_index == "æ•°æ®ç±»å‹æ¦‚è§ˆ":
            st.dataframe(dtype_info, use_container_width=True)
        elif selected_index == "æ•°æ®é¢„è§ˆ":
            if st.button("ğŸ² éšæœºæŠ½æ ·"):
                # æ·»åŠ ä¿æŠ¤æªæ–½ï¼Œé˜²æ­¢æ•°æ®è¡Œæ•°ä¸è¶³10è¡Œçš„æƒ…å†µ
                sample_size = min(10, len(df))
                if sample_size == 0:
                    st.warning("æ•°æ®ä¸ºç©ºï¼Œæ— æ³•è¿›è¡ŒæŠ½æ ·")
                    display_df = df
                else:
                    display_df = df.sample(sample_size)
                st.dataframe(display_df, use_container_width=True)
            else:
                st.dataframe(df.head(10), use_container_width=True)


def loading_business_context(agent):
    """ä¸šåŠ¡èƒŒæ™¯ä¿¡æ¯æ”¶é›†ç•Œé¢"""
    df = agent.load_df()
    if df is None:
        st.info("è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶")
        return

    st.subheader("ğŸ“‹ ä¸šåŠ¡èƒŒæ™¯ä¿¡æ¯")
    st.caption("å¡«å†™ä¸šåŠ¡èƒŒæ™¯ä¿¡æ¯æœ‰åŠ©äºç”Ÿæˆæ›´ç²¾å‡†çš„åˆ†æåœºæ™¯å’Œå»ºè®®")

    with st.expander("ğŸ’¼ ä¸šåŠ¡èƒŒæ™¯ä¿¡æ¯", expanded=True):
        context = agent.load_business_context() or {}
        
        business_scope = st.text_area(
            "ä¸šåŠ¡èŒƒå›´",
            value=context.get('business_scope', ''),
            help="æè¿°è¯¥æ•°æ®è¦†ç›–çš„ä¸šåŠ¡èŒƒå›´ï¼Œä¾‹å¦‚ï¼šå®¢æˆ·äº¤æ˜“æ•°æ®ã€äº§å“é”€å”®æ•°æ®ã€ç”¨æˆ·è¡Œä¸ºæ•°æ®ç­‰",
            height=100,
            key="business_scope_input"
        )

        data_conditions = st.text_area(
            "æ•°æ®å½¢æˆæ¡ä»¶",
            value=context.get('data_conditions', ''),
            help="æè¿°æ•°æ®æ˜¯å¦‚ä½•å½¢æˆçš„ï¼ŒåŒ…æ‹¬æ•°æ®é‡‡é›†æ–¹å¼ã€æ—¶é—´èŒƒå›´ã€ç­›é€‰æ¡ä»¶ç­‰",
            height=100,
            key="data_conditions_input"
        )

        business_domain = st.text_input(
            "ä¸šåŠ¡é¢†åŸŸ",
            value=context.get('business_domain', ''),
            help="ä¾‹å¦‚ï¼šç”µå•†ã€é‡‘èã€åŒ»ç–—ã€æ•™è‚²ç­‰",
            key="business_domain_input"
        )

        additional_info = st.text_area(
            "å…¶ä»–èƒŒæ™¯ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰",
            value=context.get('additional_info', ''),
            help="è¡¥å……å…¶ä»–æœ‰åŠ©äºç†è§£æ•°æ®çš„èƒŒæ™¯ä¿¡æ¯",
            height=80,
            key="additional_info_input"
        )

        if st.button("ğŸ’¾ ä¿å­˜ä¸šåŠ¡èƒŒæ™¯", use_container_width=True):
            context = {
                'business_scope': business_scope,
                'data_conditions': data_conditions,
                'business_domain': business_domain,
                'additional_info': additional_info
            }
            agent.save_business_context(context)
            st.success("ä¸šåŠ¡èƒŒæ™¯ä¿¡æ¯å·²ä¿å­˜ï¼")

    with st.expander("ğŸ“Š æ•°æ®è§„èŒƒä¸å…ƒæ•°æ®ï¼ˆå¯é€‰ï¼‰", expanded=False):
        data_metadata = st.text_area(
            "æ•°æ®è§„èŒƒè¯´æ˜",
            value=agent.load_data_metadata() or '',
            help="æè¿°æ•°æ®è¡¨ç»“æ„è§„èŒƒã€å­—æ®µå«ä¹‰ã€æ•°æ®è´¨é‡æ ‡å‡†ç­‰",
            height=150,
            key="data_metadata_input"
        )

        if st.button("ğŸ’¾ ä¿å­˜æ•°æ®è§„èŒƒ", use_container_width=True):
            agent.save_data_metadata(data_metadata)
            st.success("æ•°æ®è§„èŒƒå·²ä¿å­˜ï¼")


def loading_scenario_mining(agent):
    """åœºæ™¯æŒ–æ˜åŠŸèƒ½ç•Œé¢"""
    df = agent.load_df()
    if df is None:
        st.info("è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶")
        return

    st.caption("åŸºäºæ•°æ®ç»“æ„å’Œä¸šåŠ¡èƒŒæ™¯ï¼Œç”Ÿæˆå¯æŒ–æ˜çš„åˆ†æåœºæ™¯")

    col1, col2 = st.columns(2)
    show_existing = False
    
    with col1:
        generate_btn = st.button("ğŸš€ ç”ŸæˆæŒ–æ˜åœºæ™¯", use_container_width=True, type="primary")
    
    with col2:
        if agent.mining_scenarios:
            show_existing = st.button("ğŸ“„ æŸ¥çœ‹å·²æœ‰åœºæ™¯", use_container_width=True)

    if generate_btn:
        with st.spinner("æ­£åœ¨åˆ†ææ•°æ®ç»“æ„å’Œä¸šåŠ¡èƒŒæ™¯ï¼Œç”ŸæˆæŒ–æ˜åœºæ™¯..."):
            data_metadata = agent.load_data_metadata()
            business_context = agent.load_business_context()
            scenarios = agent.generate_mining_scenarios(df, data_metadata, business_context)
            agent.mining_scenarios = scenarios

        st.success("æŒ–æ˜åœºæ™¯ç”Ÿæˆå®Œæˆï¼")
        st.markdown("---")
        st.markdown(scenarios)

    if show_existing and agent.mining_scenarios:
        st.markdown("---")
        st.markdown(agent.mining_scenarios)


def loading_analysis_suggestions(agent):
    """åˆ†ææŒ–æ˜å»ºè®®åŠŸèƒ½ç•Œé¢"""
    df = agent.load_df()
    if df is None:
        st.info("è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶")
        return

    st.caption("åŸºäºæ•°æ®ç‰¹å¾ã€ä¸šåŠ¡èƒŒæ™¯å’ŒæŒ–æ˜åœºæ™¯ï¼Œç”Ÿæˆç³»ç»Ÿæ€§çš„åˆ†æå»ºè®®")

    col1, col2 = st.columns(2)
    show_existing = False
    
    with col1:
        generate_btn = st.button("ğŸ¯ ç”Ÿæˆåˆ†æå»ºè®®", use_container_width=True, type="primary")
    
    with col2:
        if agent.analysis_suggestions:
            show_existing = st.button("ğŸ“‹ æŸ¥çœ‹å·²æœ‰å»ºè®®", use_container_width=True)

    if generate_btn:
        with st.spinner("æ­£åœ¨ç”Ÿæˆåˆ†ææŒ–æ˜å»ºè®®..."):
            data_metadata = agent.load_data_metadata()
            business_context = agent.load_business_context()
            mining_scenarios = agent.mining_scenarios
            suggestions = agent.generate_analysis_suggestions(
                df, data_metadata, business_context, mining_scenarios
            )
            agent.analysis_suggestions = suggestions

        st.success("åˆ†æå»ºè®®ç”Ÿæˆå®Œæˆï¼")
        st.markdown("---")
        st.markdown(suggestions)

    if show_existing and agent.analysis_suggestions:
        st.markdown("---")
        st.markdown(agent.analysis_suggestions)


def loading_chat(agent, auto=False) -> None:

    df = agent.load_df()
    if df is None:
        return

    with st.chat_message("assistant"):
        st.write(
            "æˆ‘æ˜¯æ‚¨çš„æ•°æ®åˆ†æåŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ï¼\n\n"
            "è¯·å…ˆä¸Šä¼ æ‚¨çš„æ•°æ®æ–‡ä»¶ï¼Œä¸Šä¼ å®Œæˆåï¼Œæ‚¨å¯ä»¥åœ¨ä¸‹æ–¹å’Œæˆ‘å¯¹è¯ï¼Œä¹Ÿå¯ä»¥ç›´æ¥ç‚¹å‡»æŒ‰é’®è§£ææ•°æ®å«ä¹‰ã€‚"
        )
        analyze_btn = st.button("ğŸ” è§£æå«ä¹‰")
        result_placeholder = st.empty()
        
    # æ¸²æŸ“å†å²å¯¹è¯
    chat_history = agent.load_memory()

    for idx, entry in enumerate(chat_history):
        bubble = st.chat_message(entry["role"])
        content = entry["content"]
        if isinstance(content, str):
            bubble.write(content)

    already_generated = any(
        entry["role"] == "assistant" and "å«ä¹‰" in str(entry["content"])
        for entry in chat_history
    )

    if analyze_btn or (auto and not already_generated):
        st.chat_message("user").write("è¯·å¸®æˆ‘è§£ææ•°æ®å«ä¹‰")
        agent.add_memory({"role": "user", "content": "è¯·å¸®æˆ‘è§£ææ•°æ®å«ä¹‰"})
        with st.spinner("åˆ†æä¸­..."):
            desc = agent.do_data_description(df)

        agent.finish_auto()
        st.chat_message("assistant").write(desc)
        agent.add_memory({"role": "assistant", "content": desc})
        st.rerun()

    # ç”¨æˆ·è‡ªå®šä¹‰è¾“å…¥
    user_input = st.chat_input("è¯·è¾“å…¥éœ€æ±‚ï¼Œä¾‹å¦‚ã€Œå¸®æˆ‘åˆ†æxxåˆ—ã€")
    if user_input:
        st.chat_message("user").write(user_input)
        agent.add_memory({"role": "user", "content": user_input})
        with st.spinner("å¤„ç†ä¸­â€¦"):
            reply = agent.do_data_description(df, user_input)

        st.chat_message("assistant").write(reply)
        agent.add_memory({"role": "assistant", "content": reply})
        st.rerun()


if __name__ == "__main__":

    agent = st.session_state.data_loading_agent
    planner = st.session_state.planner_agent
    auto = planner.loading_auto

    if st.session_state.auto_mode == True:
        if (agent.finish_auto_task == True and planner.switched_prep == False) or planner.loading_auto == False:
            planner.finish_loading_auto()
            st.switch_page("workflow/preprocessing/preprocessing_render.py")

    c1,c2 = st.columns(2)
    with c1:
        st.title("æ•°æ®å¯¼å…¥")
    with c2:
        st.write("")  
        st.write("")  
        # sac.buttons([
        #     sac.ButtonsItem(label='Github', icon='github', href='https://github.com/Automated-Statistician/AutoSTAT'),
        #     sac.ButtonsItem(label='Doc', icon=sac.BsIcon(name='bi bi-file-earmark-post-fill', size=16), href='https://automated-statistician.github.io/autostatdoc.github.io/'),
        # ], align='end', color='dark', variant='filled', index=None)
    st.markdown("---")

    c = st.columns(2)
    with c[0].expander('æ•°æ®ä¸Šä¼ ', True):
        loading_data_file(agent)
    with c[1].expander('æ•°æ®å»ºè®®', True):
        loading_chat(agent, auto)
    with c[0].expander('æ•°æ®å±•ç¤º', True):
        loading_basic_info(agent)
    
    # æ–°å¢åŠŸèƒ½åŒºåŸŸ
    st.markdown("---")
    st.markdown("### ğŸ¯ æ™ºèƒ½åˆ†æè§„åˆ’")
    
    c2 = st.columns(2)
    with c2[0].expander('ä¸šåŠ¡èƒŒæ™¯ä¿¡æ¯', True):
        loading_business_context(agent)
    with c2[1].expander('åœºæ™¯æŒ–æ˜', True):
        loading_scenario_mining(agent)
    
    with st.expander('åˆ†ææŒ–æ˜å»ºè®®', True):
        loading_analysis_suggestions(agent)

